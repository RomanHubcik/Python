{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a08b1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f2abba1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.367921</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0.308872</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.296306</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.295806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.258608</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.367921</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.509927</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.170646</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.234224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.258608</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.150855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  SibSp     Parch      Fare  Female  Male  Master  Miss   Mr  \\\n",
       "298  0.367921  0.000  0.000000  0.059532     0.0   1.0     0.0   0.0  1.0   \n",
       "884  0.308872  0.000  0.000000  0.013761     0.0   1.0     0.0   0.0  1.0   \n",
       "247  0.296306  0.000  0.333333  0.028302     1.0   0.0     0.0   0.0  0.0   \n",
       "478  0.271174  0.000  0.000000  0.014680     0.0   1.0     0.0   0.0  1.0   \n",
       "305  0.006283  0.125  0.333333  0.295806     0.0   1.0     1.0   0.0  0.0   \n",
       "..        ...    ...       ...       ...     ...   ...     ...   ...  ...   \n",
       "106  0.258608  0.000  0.000000  0.014932     1.0   0.0     0.0   1.0  0.0   \n",
       "270  0.367921  0.000  0.000000  0.060508     0.0   1.0     0.0   0.0  1.0   \n",
       "860  0.509927  0.250  0.000000  0.027538     0.0   1.0     0.0   0.0  1.0   \n",
       "435  0.170646  0.125  0.333333  0.234224     1.0   0.0     0.0   1.0  0.0   \n",
       "102  0.258608  0.000  0.166667  0.150855     0.0   1.0     0.0   0.0  1.0   \n",
       "\n",
       "     Mrs  Class 1  Class 2  Class 3  \n",
       "298  0.0      1.0      0.0      0.0  \n",
       "884  0.0      0.0      0.0      1.0  \n",
       "247  1.0      0.0      1.0      0.0  \n",
       "478  0.0      0.0      0.0      1.0  \n",
       "305  0.0      1.0      0.0      0.0  \n",
       "..   ...      ...      ...      ...  \n",
       "106  0.0      0.0      0.0      1.0  \n",
       "270  0.0      1.0      0.0      0.0  \n",
       "860  0.0      0.0      0.0      1.0  \n",
       "435  0.0      1.0      0.0      0.0  \n",
       "102  0.0      1.0      0.0      0.0  \n",
       "\n",
       "[668 rows x 13 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load preprocessed train dataset\n",
    "df_train = pd.read_csv('titanic_train_preprocessed2.csv')\n",
    "\n",
    "# create matrix of the features (X) and target (y)\n",
    "X = df_train.drop('Survived',axis=1) # values used for prediction\n",
    "y = df_train['Survived'] # values to be predicted\n",
    "\n",
    "# split data from \"titanic_train_preprocessed.csv\" to training data (75%) and testing data (25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b7ce177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.asarray(X_train).astype(np.float32) # cause of error: Failed to convert a NumPy array to a Tensor\n",
    "# y_train = np.asarray(y_train).astype(np.float32) \n",
    "# X_test = np.asarray(X_test).astype(np.float32) \n",
    "# y_test = np.asarray(y_test).astype(np.float32) \n",
    "# X = np.asarray(X).astype(np.float32)\n",
    "# y = np.asarray(y).astype(np.float32)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(13,), activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6427b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "67/67 [==============================] - 1s 2ms/step - loss: 0.4688 - accuracy: 0.7934\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8129\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8174\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8234\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8293\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8353\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8234\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8443\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8263\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8293\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8338\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8353\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8263\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8219\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8338\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8308\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8323\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8338\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8308\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8323\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8413\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8353\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8308\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8368\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8308\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8368\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8383\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8443\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8368\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8398\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8323\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8398\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8368\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.8308\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8353\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8323\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8428\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8398\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8443\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8413\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8383\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8398\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8398\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8368\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8353\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8398\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8413\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8383\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8383\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8398\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8353\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8428\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8413\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8353\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8338\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8398\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8368\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8473\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8473\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8398\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8338\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8458\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8473\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8503\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8413\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8458\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8443\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8383\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8488\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8398\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8443\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8443\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8518\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8443\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8443\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8428\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8458\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8458\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8473\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8383\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8473\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8548\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8533\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8518\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8458\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8548\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8458\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8458\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8503\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8503\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8533\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8518\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8488\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8533\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8473\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8533\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8503\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8548\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8518\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1917f2e6110>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "66824737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.45134908e-01],\n",
       "       [1.05308935e-01],\n",
       "       [1.56051829e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.42497879e-01],\n",
       "       [9.99177694e-01],\n",
       "       [5.47515392e-01],\n",
       "       [1.61892951e-01],\n",
       "       [5.36262810e-01],\n",
       "       [9.86047685e-01],\n",
       "       [3.89015555e-01],\n",
       "       [9.93505493e-02],\n",
       "       [2.33495727e-01],\n",
       "       [1.46762982e-01],\n",
       "       [1.10772766e-01],\n",
       "       [9.95536923e-01],\n",
       "       [3.88404220e-01],\n",
       "       [5.47511280e-01],\n",
       "       [1.01123221e-01],\n",
       "       [3.37816447e-01],\n",
       "       [1.53863385e-01],\n",
       "       [3.32298189e-01],\n",
       "       [4.53493804e-01],\n",
       "       [1.60322666e-01],\n",
       "       [1.71258718e-01],\n",
       "       [1.71730936e-01],\n",
       "       [3.32038701e-01],\n",
       "       [1.06304400e-01],\n",
       "       [4.73181903e-01],\n",
       "       [5.45634985e-01],\n",
       "       [1.56651840e-01],\n",
       "       [5.43430924e-01],\n",
       "       [3.31388742e-01],\n",
       "       [5.47525942e-01],\n",
       "       [1.57845855e-01],\n",
       "       [1.59048736e-01],\n",
       "       [3.30654740e-01],\n",
       "       [5.47515392e-01],\n",
       "       [9.41038668e-01],\n",
       "       [1.49170175e-01],\n",
       "       [1.03024598e-02],\n",
       "       [1.34849578e-01],\n",
       "       [1.49645939e-01],\n",
       "       [1.48721486e-01],\n",
       "       [4.90836382e-01],\n",
       "       [5.39529603e-03],\n",
       "       [1.57497227e-01],\n",
       "       [1.58727109e-01],\n",
       "       [1.51181966e-01],\n",
       "       [1.11689329e-01],\n",
       "       [3.72315109e-01],\n",
       "       [9.99985516e-01],\n",
       "       [1.32699697e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.81324277e-02],\n",
       "       [9.98122513e-01],\n",
       "       [1.06445394e-01],\n",
       "       [9.99998510e-01],\n",
       "       [9.99995530e-01],\n",
       "       [5.37460089e-01],\n",
       "       [1.54883474e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.46922398e-01],\n",
       "       [3.31315368e-01],\n",
       "       [1.48721486e-01],\n",
       "       [9.99846995e-01],\n",
       "       [5.65080605e-02],\n",
       "       [1.49930045e-01],\n",
       "       [1.23309046e-01],\n",
       "       [9.99999523e-01],\n",
       "       [9.93021488e-01],\n",
       "       [9.99935210e-01],\n",
       "       [3.31803888e-01],\n",
       "       [9.96786118e-01],\n",
       "       [1.54224768e-01],\n",
       "       [1.45818263e-01],\n",
       "       [5.46442032e-01],\n",
       "       [9.95859683e-01],\n",
       "       [9.99989688e-01],\n",
       "       [4.36189353e-01],\n",
       "       [3.44117768e-02],\n",
       "       [9.91388798e-01],\n",
       "       [9.99851763e-01],\n",
       "       [1.48683071e-01],\n",
       "       [3.20522308e-01],\n",
       "       [4.29040849e-01],\n",
       "       [9.99629378e-01],\n",
       "       [9.93498504e-01],\n",
       "       [2.89976597e-01],\n",
       "       [1.47191226e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.25560576e-01],\n",
       "       [3.22059423e-01],\n",
       "       [1.48657575e-01],\n",
       "       [1.49170205e-01],\n",
       "       [1.51046962e-01],\n",
       "       [3.87844503e-01],\n",
       "       [9.32801142e-02],\n",
       "       [9.95678186e-01],\n",
       "       [1.52187943e-01],\n",
       "       [3.32320839e-01],\n",
       "       [1.38955384e-01],\n",
       "       [9.99700844e-01],\n",
       "       [1.26808822e-01],\n",
       "       [1.48697123e-01],\n",
       "       [1.42994672e-01],\n",
       "       [9.99121130e-01],\n",
       "       [3.33417207e-01],\n",
       "       [1.53871909e-01],\n",
       "       [3.33769262e-01],\n",
       "       [9.99979079e-01],\n",
       "       [1.53559685e-01],\n",
       "       [9.99979913e-01],\n",
       "       [3.32537651e-01],\n",
       "       [4.48491797e-02],\n",
       "       [1.62424415e-01],\n",
       "       [4.21609372e-01],\n",
       "       [1.10713825e-01],\n",
       "       [9.92265880e-01],\n",
       "       [7.42311543e-03],\n",
       "       [5.03269536e-03],\n",
       "       [9.97789085e-01],\n",
       "       [9.95913625e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.51265487e-01],\n",
       "       [3.32393467e-01],\n",
       "       [9.99998868e-01],\n",
       "       [2.98878133e-01],\n",
       "       [6.31138206e-01],\n",
       "       [1.55761346e-01],\n",
       "       [5.47508657e-01],\n",
       "       [4.45134908e-01],\n",
       "       [9.97007489e-02],\n",
       "       [7.18710482e-01],\n",
       "       [3.90177041e-01],\n",
       "       [7.60037243e-01],\n",
       "       [9.99738276e-01],\n",
       "       [1.49620697e-01],\n",
       "       [1.09612055e-01],\n",
       "       [7.27141023e-01],\n",
       "       [1.56991750e-01],\n",
       "       [9.95391667e-01],\n",
       "       [1.02428727e-01],\n",
       "       [8.82140547e-02],\n",
       "       [9.30266560e-06],\n",
       "       [9.97407734e-01],\n",
       "       [1.05092935e-01],\n",
       "       [9.96921360e-02],\n",
       "       [9.99984741e-01],\n",
       "       [1.05149955e-01],\n",
       "       [1.51704207e-01],\n",
       "       [1.52590454e-01],\n",
       "       [1.57025695e-01],\n",
       "       [4.88418400e-01],\n",
       "       [1.49645939e-01],\n",
       "       [1.46582752e-01],\n",
       "       [3.52304429e-01],\n",
       "       [5.47513425e-01],\n",
       "       [9.64481950e-01],\n",
       "       [4.76442069e-01],\n",
       "       [1.52036235e-01],\n",
       "       [3.31387430e-01],\n",
       "       [1.10797286e-01],\n",
       "       [9.99979496e-01],\n",
       "       [1.50911719e-01],\n",
       "       [2.50915289e-01],\n",
       "       [9.50787514e-02],\n",
       "       [9.99979079e-01],\n",
       "       [1.54787660e-01],\n",
       "       [1.38721287e-01],\n",
       "       [3.05561721e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.32561165e-01],\n",
       "       [4.36926633e-01],\n",
       "       [1.55567676e-01],\n",
       "       [1.47115037e-01],\n",
       "       [4.06171876e-06],\n",
       "       [9.99999166e-01],\n",
       "       [6.51848197e-01],\n",
       "       [3.29159617e-01],\n",
       "       [9.53657702e-02],\n",
       "       [1.46489218e-01],\n",
       "       [1.41716570e-01],\n",
       "       [2.26062849e-01],\n",
       "       [6.63156062e-02],\n",
       "       [3.28449339e-01],\n",
       "       [8.62657651e-02],\n",
       "       [1.49170175e-01],\n",
       "       [3.30784172e-01],\n",
       "       [9.98423696e-01],\n",
       "       [6.51513860e-02],\n",
       "       [1.08298481e-01],\n",
       "       [1.49891794e-01],\n",
       "       [1.55104056e-01],\n",
       "       [9.99934077e-01],\n",
       "       [9.99992967e-01],\n",
       "       [9.99998808e-01],\n",
       "       [1.09705776e-01],\n",
       "       [9.99456704e-01],\n",
       "       [2.17796281e-01],\n",
       "       [2.42898203e-02],\n",
       "       [5.47102988e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.21823585e-01],\n",
       "       [1.53835908e-01],\n",
       "       [6.84326589e-01],\n",
       "       [1.55049354e-01],\n",
       "       [2.00505257e-01],\n",
       "       [1.71110854e-01],\n",
       "       [6.35931939e-02],\n",
       "       [1.90492436e-01],\n",
       "       [1.46839008e-01],\n",
       "       [9.98652101e-01],\n",
       "       [1.48644656e-01],\n",
       "       [2.33495727e-01],\n",
       "       [1.09126821e-01],\n",
       "       [9.99999285e-01],\n",
       "       [2.75195032e-01],\n",
       "       [9.99463975e-01],\n",
       "       [1.47191226e-01],\n",
       "       [1.49170175e-01],\n",
       "       [9.99998331e-01],\n",
       "       [1.47161439e-01]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "#y_pred = np.asarray(y_pred).astype(np.int64)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7bd629fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the accuracy of the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score \n\u001b[1;32m----> 3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "28bdb758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8429\n",
      "Epoch 2/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8361\n",
      "Epoch 3/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8373\n",
      "Epoch 4/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8429\n",
      "Epoch 5/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8440\n",
      "Epoch 6/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8462\n",
      "Epoch 7/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8474\n",
      "Epoch 8/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8451\n",
      "Epoch 9/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8474\n",
      "Epoch 10/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8440\n",
      "Epoch 11/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8507\n",
      "Epoch 12/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8474\n",
      "Epoch 13/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8496\n",
      "Epoch 14/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8451\n",
      "Epoch 15/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8462\n",
      "Epoch 16/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8474\n",
      "Epoch 17/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8485\n",
      "Epoch 18/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8507\n",
      "Epoch 19/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8462\n",
      "Epoch 20/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8485\n",
      "Epoch 21/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8519\n",
      "Epoch 22/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8563\n",
      "Epoch 23/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8507\n",
      "Epoch 24/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8541\n",
      "Epoch 25/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8519\n",
      "Epoch 26/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8451\n",
      "Epoch 27/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8440\n",
      "Epoch 28/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8541\n",
      "Epoch 29/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8519\n",
      "Epoch 30/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8530\n",
      "Epoch 31/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8496\n",
      "Epoch 32/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8429\n",
      "Epoch 33/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8485\n",
      "Epoch 34/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8429\n",
      "Epoch 35/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8519\n",
      "Epoch 36/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8541\n",
      "Epoch 37/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8530\n",
      "Epoch 38/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8552\n",
      "Epoch 39/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8485\n",
      "Epoch 40/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8507\n",
      "Epoch 41/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8451\n",
      "Epoch 42/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8519\n",
      "Epoch 43/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8519\n",
      "Epoch 44/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8519\n",
      "Epoch 45/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8496\n",
      "Epoch 46/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8530\n",
      "Epoch 47/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8507\n",
      "Epoch 48/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8597\n",
      "Epoch 49/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8519\n",
      "Epoch 50/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8541\n",
      "Epoch 51/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8552\n",
      "Epoch 52/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8575\n",
      "Epoch 53/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8586\n",
      "Epoch 54/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8586\n",
      "Epoch 55/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8552\n",
      "Epoch 56/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8507\n",
      "Epoch 57/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8541\n",
      "Epoch 58/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8507\n",
      "Epoch 59/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8485\n",
      "Epoch 60/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8530\n",
      "Epoch 61/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8507\n",
      "Epoch 62/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8563\n",
      "Epoch 63/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8563\n",
      "Epoch 64/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8597\n",
      "Epoch 65/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8608\n",
      "Epoch 66/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8541\n",
      "Epoch 67/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8530\n",
      "Epoch 68/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8586\n",
      "Epoch 69/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8519\n",
      "Epoch 70/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8530\n",
      "Epoch 71/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8552\n",
      "Epoch 72/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8507\n",
      "Epoch 73/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8541\n",
      "Epoch 74/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8586\n",
      "Epoch 75/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8586\n",
      "Epoch 76/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8519\n",
      "Epoch 77/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8563\n",
      "Epoch 78/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8597\n",
      "Epoch 79/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8552\n",
      "Epoch 80/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8552\n",
      "Epoch 81/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8620\n",
      "Epoch 82/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8563\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.8563\n",
      "Epoch 84/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8563\n",
      "Epoch 85/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8642\n",
      "Epoch 86/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8541\n",
      "Epoch 87/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8519\n",
      "Epoch 88/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8608\n",
      "Epoch 89/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8586\n",
      "Epoch 90/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8608\n",
      "Epoch 91/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8563\n",
      "Epoch 92/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8642\n",
      "Epoch 93/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8552\n",
      "Epoch 94/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8597\n",
      "Epoch 95/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8586\n",
      "Epoch 96/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8541\n",
      "Epoch 97/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8597\n",
      "Epoch 98/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8597\n",
      "Epoch 99/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8575\n",
      "Epoch 100/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8597\n",
      "Epoch 101/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8586\n",
      "Epoch 102/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8507\n",
      "Epoch 103/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8507\n",
      "Epoch 104/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8620\n",
      "Epoch 105/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8575\n",
      "Epoch 106/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8642\n",
      "Epoch 107/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8563\n",
      "Epoch 108/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8631\n",
      "Epoch 109/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8620\n",
      "Epoch 110/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8631\n",
      "Epoch 111/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8541\n",
      "Epoch 112/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8575\n",
      "Epoch 113/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8575\n",
      "Epoch 114/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8597\n",
      "Epoch 115/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8563\n",
      "Epoch 116/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8530\n",
      "Epoch 117/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8631\n",
      "Epoch 118/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8541\n",
      "Epoch 119/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8653\n",
      "Epoch 120/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8608\n",
      "Epoch 121/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3148 - accuracy: 0.8631\n",
      "Epoch 122/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8620\n",
      "Epoch 123/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8597\n",
      "Epoch 124/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8608\n",
      "Epoch 125/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8586\n",
      "Epoch 126/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.8597\n",
      "Epoch 127/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8597\n",
      "Epoch 128/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8563\n",
      "Epoch 129/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8687\n",
      "Epoch 130/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8687\n",
      "Epoch 131/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8664\n",
      "Epoch 132/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8597\n",
      "Epoch 133/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8676\n",
      "Epoch 134/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8631\n",
      "Epoch 135/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8664\n",
      "Epoch 136/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8608\n",
      "Epoch 137/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8631\n",
      "Epoch 138/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8575\n",
      "Epoch 139/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8519\n",
      "Epoch 140/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8631\n",
      "Epoch 141/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8653\n",
      "Epoch 142/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8485\n",
      "Epoch 143/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8642\n",
      "Epoch 144/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8664\n",
      "Epoch 145/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8664\n",
      "Epoch 146/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8676\n",
      "Epoch 147/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8620\n",
      "Epoch 148/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8653\n",
      "Epoch 149/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8597\n",
      "Epoch 150/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8519\n",
      "Epoch 151/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8586\n",
      "Epoch 152/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8575\n",
      "Epoch 153/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8653\n",
      "Epoch 154/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8653\n",
      "Epoch 155/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8608\n",
      "Epoch 156/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8586\n",
      "Epoch 157/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8552\n",
      "Epoch 158/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8586\n",
      "Epoch 159/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8631\n",
      "Epoch 160/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8721\n",
      "Epoch 161/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8631\n",
      "Epoch 162/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8687\n",
      "Epoch 163/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8586\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8676\n",
      "Epoch 165/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8653\n",
      "Epoch 166/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8642\n",
      "Epoch 167/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8586\n",
      "Epoch 168/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8575\n",
      "Epoch 169/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8586\n",
      "Epoch 170/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8754\n",
      "Epoch 171/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8575\n",
      "Epoch 172/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8676\n",
      "Epoch 173/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8664\n",
      "Epoch 174/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3074 - accuracy: 0.8631\n",
      "Epoch 175/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8631\n",
      "Epoch 176/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8676\n",
      "Epoch 177/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8664\n",
      "Epoch 178/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8676\n",
      "Epoch 179/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8698\n",
      "Epoch 180/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8642\n",
      "Epoch 181/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8698\n",
      "Epoch 182/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8687\n",
      "Epoch 183/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8597\n",
      "Epoch 184/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8575\n",
      "Epoch 185/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8597\n",
      "Epoch 186/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8653\n",
      "Epoch 187/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8676\n",
      "Epoch 188/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8709\n",
      "Epoch 189/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8653\n",
      "Epoch 190/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8631\n",
      "Epoch 191/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8541\n",
      "Epoch 192/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8653\n",
      "Epoch 193/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8608\n",
      "Epoch 194/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8653\n",
      "Epoch 195/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8620\n",
      "Epoch 196/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8642\n",
      "Epoch 197/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8597\n",
      "Epoch 198/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8608\n",
      "Epoch 199/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.8620\n",
      "Epoch 200/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8732\n",
      "Epoch 201/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8664\n",
      "Epoch 202/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8743\n",
      "Epoch 203/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8664\n",
      "Epoch 204/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8563\n",
      "Epoch 205/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8620\n",
      "Epoch 206/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8664\n",
      "Epoch 207/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8664\n",
      "Epoch 208/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8743\n",
      "Epoch 209/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8642\n",
      "Epoch 210/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8709\n",
      "Epoch 211/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8608\n",
      "Epoch 212/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8608\n",
      "Epoch 213/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8698\n",
      "Epoch 214/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8631\n",
      "Epoch 215/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8642\n",
      "Epoch 216/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8676\n",
      "Epoch 217/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8597\n",
      "Epoch 218/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8653\n",
      "Epoch 219/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8642\n",
      "Epoch 220/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8698\n",
      "Epoch 221/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8687\n",
      "Epoch 222/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.8664\n",
      "Epoch 223/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8687\n",
      "Epoch 224/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8608\n",
      "Epoch 225/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8631\n",
      "Epoch 226/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8653\n",
      "Epoch 227/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8676\n",
      "Epoch 228/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8698\n",
      "Epoch 229/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8631\n",
      "Epoch 230/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.8676\n",
      "Epoch 231/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8552\n",
      "Epoch 232/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8653\n",
      "Epoch 233/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8597\n",
      "Epoch 234/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.8687\n",
      "Epoch 235/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8597\n",
      "Epoch 236/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8642\n",
      "Epoch 237/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8653\n",
      "Epoch 238/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8709\n",
      "Epoch 239/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8664\n",
      "Epoch 240/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8698\n",
      "Epoch 241/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8642\n",
      "Epoch 242/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8721\n",
      "Epoch 243/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8608\n",
      "Epoch 244/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.8608\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8653\n",
      "Epoch 246/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8687\n",
      "Epoch 247/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8620\n",
      "Epoch 248/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8721\n",
      "Epoch 249/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8732\n",
      "Epoch 250/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8642\n",
      "Epoch 251/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8642\n",
      "Epoch 252/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8687\n",
      "Epoch 253/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8597\n",
      "Epoch 254/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8631\n",
      "Epoch 255/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8664\n",
      "Epoch 256/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8620\n",
      "Epoch 257/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8687\n",
      "Epoch 258/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8608\n",
      "Epoch 259/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8664\n",
      "Epoch 260/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8664\n",
      "Epoch 261/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8709\n",
      "Epoch 262/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8743\n",
      "Epoch 263/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8754\n",
      "Epoch 264/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8687\n",
      "Epoch 265/300\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8664\n",
      "Epoch 266/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8687\n",
      "Epoch 267/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8687\n",
      "Epoch 268/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.8732\n",
      "Epoch 269/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8642\n",
      "Epoch 270/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8608\n",
      "Epoch 271/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8664\n",
      "Epoch 272/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8653\n",
      "Epoch 273/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8698\n",
      "Epoch 274/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8642\n",
      "Epoch 275/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.8721\n",
      "Epoch 276/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8709\n",
      "Epoch 277/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8698\n",
      "Epoch 278/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8676\n",
      "Epoch 279/300\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8608\n",
      "Epoch 280/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8687\n",
      "Epoch 281/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8631\n",
      "Epoch 282/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8698\n",
      "Epoch 283/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8631\n",
      "Epoch 284/300\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8676\n",
      "Epoch 285/300\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8709\n",
      "Epoch 286/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8620\n",
      "Epoch 287/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8586\n",
      "Epoch 288/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8687\n",
      "Epoch 289/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8620\n",
      "Epoch 290/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8698\n",
      "Epoch 291/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8765\n",
      "Epoch 292/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8608\n",
      "Epoch 293/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8653\n",
      "Epoch 294/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8664\n",
      "Epoch 295/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8698\n",
      "Epoch 296/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8721\n",
      "Epoch 297/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.8676\n",
      "Epoch 298/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8664\n",
      "Epoch 299/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.8754\n",
      "Epoch 300/300\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1917fe7d7d0>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once happy with the model accuracy, fit it on all data\n",
    "model.fit(X, y, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "20d520e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.452723</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287881</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.396975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.512066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.505473</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.396975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.396975</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  SibSp     Parch      Fare  Female  Male  Master  Miss   Mr  \\\n",
       "0    0.452723  0.000  0.000000  0.015282     0.0   1.0     0.0   0.0  1.0   \n",
       "1    0.617566  0.125  0.000000  0.013663     1.0   0.0     0.0   0.0  0.0   \n",
       "2    0.815377  0.000  0.000000  0.018909     0.0   1.0     0.0   0.0  1.0   \n",
       "3    0.353818  0.000  0.000000  0.016908     0.0   1.0     0.0   0.0  1.0   \n",
       "4    0.287881  0.125  0.111111  0.023984     1.0   0.0     0.0   0.0  0.0   \n",
       "..        ...    ...       ...       ...     ...   ...     ...   ...  ...   \n",
       "413  0.396975  0.000  0.000000  0.015713     0.0   1.0     0.0   0.0  1.0   \n",
       "414  0.512066  0.000  0.000000  0.212559     1.0   0.0     0.0   0.0  0.0   \n",
       "415  0.505473  0.000  0.000000  0.014151     0.0   1.0     0.0   0.0  1.0   \n",
       "416  0.396975  0.000  0.000000  0.015713     0.0   1.0     0.0   0.0  1.0   \n",
       "417  0.396975  0.125  0.111111  0.043640     0.0   1.0     1.0   0.0  0.0   \n",
       "\n",
       "     Mrs  Class 1  Class 2  Class 3  \n",
       "0    0.0      0.0      0.0      1.0  \n",
       "1    1.0      0.0      0.0      1.0  \n",
       "2    0.0      0.0      1.0      0.0  \n",
       "3    0.0      0.0      0.0      1.0  \n",
       "4    1.0      0.0      0.0      1.0  \n",
       "..   ...      ...      ...      ...  \n",
       "413  0.0      0.0      0.0      1.0  \n",
       "414  1.0      1.0      0.0      0.0  \n",
       "415  0.0      0.0      0.0      1.0  \n",
       "416  0.0      0.0      0.0      1.0  \n",
       "417  0.0      0.0      0.0      1.0  \n",
       "\n",
       "[418 rows x 13 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = pd.read_csv('titanic_test_preprocessed2.csv')\n",
    "X_pred.replace([np.inf, -np.inf], np.nan, inplace=True) # becaouse of error NaN/inf\n",
    "X_pred.fillna(999, inplace=True) # becaouse of error NaN/inf\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "40b5ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pred_convert = np.nan_to_num(X_pred) # conversion, otherwise y_pred throws an error\n",
    "# X_pred_convert = np.asarray(X_pred_convert).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "967b908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.11557449],\n",
       "       [0.00013106],\n",
       "       [0.33216178],\n",
       "       [0.11906666],\n",
       "       [0.36492923],\n",
       "       [0.10452384],\n",
       "       [0.664481  ],\n",
       "       [0.00593467],\n",
       "       [0.9849225 ],\n",
       "       [0.09220599],\n",
       "       [0.1174166 ],\n",
       "       [0.39302847],\n",
       "       [1.        ],\n",
       "       [0.00331487],\n",
       "       [1.        ],\n",
       "       [0.95363754],\n",
       "       [0.1366596 ],\n",
       "       [0.11643771],\n",
       "       [0.5484095 ],\n",
       "       [0.37425014],\n",
       "       [0.3593034 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.1975113 ],\n",
       "       [1.        ],\n",
       "       [0.00019491],\n",
       "       [1.        ],\n",
       "       [0.11676679],\n",
       "       [0.39721933],\n",
       "       [0.22746636],\n",
       "       [0.00328048],\n",
       "       [0.00005256],\n",
       "       [0.55843943],\n",
       "       [0.3372592 ],\n",
       "       [0.4656812 ],\n",
       "       [0.11460559],\n",
       "       [0.666078  ],\n",
       "       [0.57964545],\n",
       "       [0.11972098],\n",
       "       [0.7287339 ],\n",
       "       [0.05155975],\n",
       "       [0.49493098],\n",
       "       [0.11712512],\n",
       "       [0.9999018 ],\n",
       "       [1.        ],\n",
       "       [0.11814193],\n",
       "       [0.3712831 ],\n",
       "       [0.1172818 ],\n",
       "       [1.        ],\n",
       "       [0.47904453],\n",
       "       [0.43281123],\n",
       "       [0.11091325],\n",
       "       [0.9999998 ],\n",
       "       [1.        ],\n",
       "       [0.12744538],\n",
       "       [0.00000005],\n",
       "       [0.1155846 ],\n",
       "       [0.11786807],\n",
       "       [0.1114606 ],\n",
       "       [1.        ],\n",
       "       [0.11320352],\n",
       "       [0.13081127],\n",
       "       [0.11475103],\n",
       "       [0.58091503],\n",
       "       [1.        ],\n",
       "       [0.9999336 ],\n",
       "       [0.6138999 ],\n",
       "       [0.19317763],\n",
       "       [0.473596  ],\n",
       "       [1.        ],\n",
       "       [0.59493005],\n",
       "       [0.11707433],\n",
       "       [0.6555445 ],\n",
       "       [0.4880312 ],\n",
       "       [1.        ],\n",
       "       [0.        ],\n",
       "       [0.11755925],\n",
       "       [1.        ],\n",
       "       [0.12286989],\n",
       "       [0.59493005],\n",
       "       [1.        ],\n",
       "       [0.9999998 ],\n",
       "       [0.3076746 ],\n",
       "       [0.1174166 ],\n",
       "       [0.11989266],\n",
       "       [0.11007104],\n",
       "       [0.63302046],\n",
       "       [0.6139347 ],\n",
       "       [0.6665575 ],\n",
       "       [1.        ],\n",
       "       [0.55988616],\n",
       "       [0.1173049 ],\n",
       "       [0.9933151 ],\n",
       "       [0.11755925],\n",
       "       [0.5102217 ],\n",
       "       [0.1180132 ],\n",
       "       [1.        ],\n",
       "       [0.11820279],\n",
       "       [0.5864036 ],\n",
       "       [0.11617554],\n",
       "       [1.        ],\n",
       "       [0.08316285],\n",
       "       [0.1172818 ],\n",
       "       [0.11819526],\n",
       "       [0.8593241 ],\n",
       "       [0.13505498],\n",
       "       [0.117003  ],\n",
       "       [0.1172818 ],\n",
       "       [0.11817394],\n",
       "       [0.0738396 ],\n",
       "       [0.11173619],\n",
       "       [0.6665108 ],\n",
       "       [0.7728171 ],\n",
       "       [0.60478944],\n",
       "       [1.        ],\n",
       "       [0.10970881],\n",
       "       [0.1160368 ],\n",
       "       [0.9552567 ],\n",
       "       [0.07840381],\n",
       "       [0.915799  ],\n",
       "       [0.99897695],\n",
       "       [0.10441294],\n",
       "       [1.        ],\n",
       "       [0.1176872 ],\n",
       "       [0.1172818 ],\n",
       "       [0.24626708],\n",
       "       [0.11719944],\n",
       "       [0.99572664],\n",
       "       [0.11872885],\n",
       "       [0.11804502],\n",
       "       [0.11662383],\n",
       "       [0.10202081],\n",
       "       [0.659074  ],\n",
       "       [0.10341629],\n",
       "       [0.11702748],\n",
       "       [0.11785012],\n",
       "       [0.11765987],\n",
       "       [0.10419701],\n",
       "       [0.58448035],\n",
       "       [0.        ],\n",
       "       [0.00001348],\n",
       "       [1.        ],\n",
       "       [0.6963559 ],\n",
       "       [0.07598607],\n",
       "       [0.42764142],\n",
       "       [0.00080483],\n",
       "       [0.27535263],\n",
       "       [0.11744168],\n",
       "       [0.49493098],\n",
       "       [0.00511362],\n",
       "       [1.        ],\n",
       "       [0.1174166 ],\n",
       "       [1.        ],\n",
       "       [0.4499705 ],\n",
       "       [0.00004676],\n",
       "       [0.11754788],\n",
       "       [1.        ],\n",
       "       [0.58502334],\n",
       "       [0.42764142],\n",
       "       [0.97177047],\n",
       "       [0.6665842 ],\n",
       "       [1.        ],\n",
       "       [0.8694896 ],\n",
       "       [0.11657067],\n",
       "       [0.12436819],\n",
       "       [0.36986896],\n",
       "       [0.10644577],\n",
       "       [0.04431611],\n",
       "       [1.        ],\n",
       "       [0.5779888 ],\n",
       "       [0.11709476],\n",
       "       [0.11765882],\n",
       "       [0.11609678],\n",
       "       [0.11678883],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [0.9801626 ],\n",
       "       [0.3930428 ],\n",
       "       [0.9999904 ],\n",
       "       [1.        ],\n",
       "       [0.12286989],\n",
       "       [0.3430781 ],\n",
       "       [0.99999547],\n",
       "       [0.1172818 ],\n",
       "       [1.        ],\n",
       "       [0.1106822 ],\n",
       "       [0.9815862 ],\n",
       "       [0.04078643],\n",
       "       [0.        ],\n",
       "       [0.1289145 ],\n",
       "       [0.07098085],\n",
       "       [0.50032204],\n",
       "       [1.        ],\n",
       "       [0.3012257 ],\n",
       "       [1.        ],\n",
       "       [0.11598049],\n",
       "       [1.        ],\n",
       "       [0.6138787 ],\n",
       "       [0.08812431],\n",
       "       [0.7869572 ],\n",
       "       [0.6539557 ],\n",
       "       [1.        ],\n",
       "       [0.99678737],\n",
       "       [1.        ],\n",
       "       [0.09570692],\n",
       "       [0.502854  ],\n",
       "       [0.57293135],\n",
       "       [0.09171148],\n",
       "       [0.9576437 ],\n",
       "       [0.11811282],\n",
       "       [0.13442573],\n",
       "       [0.11661824],\n",
       "       [0.00000417],\n",
       "       [0.88242626],\n",
       "       [0.00000064],\n",
       "       [0.26569155],\n",
       "       [0.6663511 ],\n",
       "       [0.9974695 ],\n",
       "       [1.        ],\n",
       "       [0.11755925],\n",
       "       [0.94755656],\n",
       "       [0.11722109],\n",
       "       [0.9999854 ],\n",
       "       [0.11697923],\n",
       "       [1.        ],\n",
       "       [0.88782   ],\n",
       "       [0.1174671 ],\n",
       "       [0.6665575 ],\n",
       "       [0.12606263],\n",
       "       [0.13689128],\n",
       "       [0.00000678],\n",
       "       [0.9999993 ],\n",
       "       [0.1102674 ],\n",
       "       [0.11740122],\n",
       "       [0.48020604],\n",
       "       [0.11678396],\n",
       "       [0.22017865],\n",
       "       [0.11608359],\n",
       "       [0.9998516 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.9998075 ],\n",
       "       [0.01044425],\n",
       "       [0.11740888],\n",
       "       [0.99999654],\n",
       "       [0.48757872],\n",
       "       [0.99999124],\n",
       "       [0.00016862],\n",
       "       [0.915799  ],\n",
       "       [0.6387997 ],\n",
       "       [1.        ],\n",
       "       [0.11686561],\n",
       "       [0.01197886],\n",
       "       [0.119321  ],\n",
       "       [0.11785189],\n",
       "       [0.11709473],\n",
       "       [0.1172818 ],\n",
       "       [0.11846655],\n",
       "       [0.9389994 ],\n",
       "       [0.11695946],\n",
       "       [0.1417145 ],\n",
       "       [0.11703476],\n",
       "       [0.9997348 ],\n",
       "       [0.9461989 ],\n",
       "       [0.12250963],\n",
       "       [0.1174166 ],\n",
       "       [0.06977969],\n",
       "       [0.11709476],\n",
       "       [0.666078  ],\n",
       "       [0.1140587 ],\n",
       "       [0.02531906],\n",
       "       [0.1172818 ],\n",
       "       [1.        ],\n",
       "       [0.7885095 ],\n",
       "       [0.11678482],\n",
       "       [0.98218787],\n",
       "       [0.10939954],\n",
       "       [0.02505661],\n",
       "       [0.09856789],\n",
       "       [0.084945  ],\n",
       "       [0.5827804 ],\n",
       "       [1.        ],\n",
       "       [0.6665575 ],\n",
       "       [0.22741008],\n",
       "       [0.9191559 ],\n",
       "       [0.11477241],\n",
       "       [0.11680865],\n",
       "       [0.4252715 ],\n",
       "       [0.11678883],\n",
       "       [0.11755925],\n",
       "       [0.3708827 ],\n",
       "       [0.66556877],\n",
       "       [0.11678883],\n",
       "       [0.25962004],\n",
       "       [0.11719095],\n",
       "       [0.1183147 ],\n",
       "       [1.        ],\n",
       "       [0.22746636],\n",
       "       [0.32174844],\n",
       "       [0.11813752],\n",
       "       [0.11634804],\n",
       "       [0.126691  ],\n",
       "       [0.00808949],\n",
       "       [0.1186565 ],\n",
       "       [0.6665575 ],\n",
       "       [1.        ],\n",
       "       [0.0047673 ],\n",
       "       [1.        ],\n",
       "       [0.12257797],\n",
       "       [0.00026201],\n",
       "       [0.11572359],\n",
       "       [0.11665703],\n",
       "       [0.11711862],\n",
       "       [0.4470616 ],\n",
       "       [1.        ],\n",
       "       [0.6335626 ],\n",
       "       [0.9972152 ],\n",
       "       [0.07570454],\n",
       "       [0.11827324],\n",
       "       [0.00003642],\n",
       "       [0.11819526],\n",
       "       [0.1174501 ],\n",
       "       [0.10419701],\n",
       "       [0.48787206],\n",
       "       [1.        ],\n",
       "       [0.11673576],\n",
       "       [1.        ],\n",
       "       [0.0192764 ],\n",
       "       [0.09645897],\n",
       "       [0.0842993 ],\n",
       "       [0.9999218 ],\n",
       "       [0.4223395 ],\n",
       "       [0.11678482],\n",
       "       [0.5878988 ],\n",
       "       [0.11831397],\n",
       "       [0.50102556],\n",
       "       [0.13007031],\n",
       "       [0.00023169],\n",
       "       [0.04494848],\n",
       "       [1.        ],\n",
       "       [0.07122015],\n",
       "       [0.11615203],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [0.999999  ],\n",
       "       [0.65937585],\n",
       "       [0.10419701],\n",
       "       [0.72949994],\n",
       "       [0.09557854],\n",
       "       [0.8857625 ],\n",
       "       [1.        ],\n",
       "       [0.09570692],\n",
       "       [0.00000564],\n",
       "       [0.00000064],\n",
       "       [0.9997829 ],\n",
       "       [0.26056984],\n",
       "       [1.        ],\n",
       "       [0.11740122],\n",
       "       [0.1172818 ],\n",
       "       [0.63807887],\n",
       "       [0.        ],\n",
       "       [0.92084324],\n",
       "       [0.9999249 ],\n",
       "       [0.11906666],\n",
       "       [1.        ],\n",
       "       [0.02651211],\n",
       "       [0.1100745 ],\n",
       "       [0.56860256],\n",
       "       [1.        ],\n",
       "       [0.11979923],\n",
       "       [0.04557965],\n",
       "       [1.        ],\n",
       "       [0.03323664],\n",
       "       [0.10571978],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.50832397],\n",
       "       [0.08301155],\n",
       "       [0.02524196],\n",
       "       [0.00565863],\n",
       "       [0.1172818 ],\n",
       "       [0.11829828],\n",
       "       [0.7916868 ],\n",
       "       [0.5310101 ],\n",
       "       [0.12366008],\n",
       "       [1.        ],\n",
       "       [0.11777136],\n",
       "       [0.223977  ],\n",
       "       [0.1169357 ],\n",
       "       [0.00000027],\n",
       "       [0.03887317],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.13071677],\n",
       "       [0.00216206],\n",
       "       [0.9999974 ],\n",
       "       [0.11725046],\n",
       "       [1.        ],\n",
       "       [0.11717964],\n",
       "       [0.11677232],\n",
       "       [1.        ],\n",
       "       [0.05206259],\n",
       "       [1.        ],\n",
       "       [0.29027766],\n",
       "       [0.46907058],\n",
       "       [0.08015802],\n",
       "       [0.05506095],\n",
       "       [0.9953796 ],\n",
       "       [0.66660416],\n",
       "       [0.81484056],\n",
       "       [0.6665575 ],\n",
       "       [1.        ],\n",
       "       [0.6457853 ],\n",
       "       [0.11755925],\n",
       "       [1.        ],\n",
       "       [0.11536679],\n",
       "       [0.11755925],\n",
       "       [0.9999998 ]], dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all = model.predict(X_pred)\n",
    "#predicted_data = pd.DataFrame(y_pred_all)\n",
    "np.set_printoptions(suppress=True)\n",
    "y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c1687ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all = [0 if i <=0.5 else 1 for i in y_pred_all]\n",
    "y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0b1c7e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert numpy ndarray back to dataframe\n",
    "predicted_data = pd.DataFrame(y_pred_all)\n",
    "\n",
    "# append the predicted data to final file\n",
    "df_test = pd.read_csv('titanic_test_data.csv')\n",
    "df_test = pd.concat([df_test,predicted_data],axis=1) # append predicted y\n",
    "df_test = df_test.rename(columns = {0:'Survived'}) # rename added column\n",
    "df_test = df_test[['PassengerId', 'Survived']] # leave only requested columns for submit\n",
    "df_test # check if correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ff26c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "df_test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a4f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
