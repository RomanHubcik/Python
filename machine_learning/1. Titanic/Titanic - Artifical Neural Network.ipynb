{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a08b1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f2abba1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5208</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>41.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>14.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  SibSp  Parch      Fare  female   male  Master   Miss     Mr  \\\n",
       "298  28.00      0      0   30.5000   False   True   False  False   True   \n",
       "884  25.00      0      0    7.0500   False   True   False  False   True   \n",
       "247  24.00      0      2   14.5000    True  False   False  False  False   \n",
       "478  22.00      0      0    7.5208   False   True   False  False   True   \n",
       "305   0.92      1      2  151.5500   False   True    True  False  False   \n",
       "..     ...    ...    ...       ...     ...    ...     ...    ...    ...   \n",
       "106  21.00      0      0    7.6500    True  False   False   True  False   \n",
       "270  28.00      0      0   31.0000   False   True   False  False   True   \n",
       "860  41.00      2      0   14.1083   False   True   False  False   True   \n",
       "435  14.00      1      2  120.0000    True  False   False   True  False   \n",
       "102  21.00      0      1   77.2875   False   True   False  False   True   \n",
       "\n",
       "       Mrs      1      2      3  \n",
       "298  False   True  False  False  \n",
       "884  False  False  False   True  \n",
       "247   True  False   True  False  \n",
       "478  False  False  False   True  \n",
       "305  False   True  False  False  \n",
       "..     ...    ...    ...    ...  \n",
       "106  False  False  False   True  \n",
       "270  False   True  False  False  \n",
       "860  False  False  False   True  \n",
       "435  False   True  False  False  \n",
       "102  False   True  False  False  \n",
       "\n",
       "[668 rows x 13 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load preprocessed train dataset\n",
    "df_train = pd.read_csv('titanic_train_preprocessed2.csv')\n",
    "\n",
    "# create matrix of the features (X) and target (y)\n",
    "X = df_train.drop('Survived',axis=1) # values used for prediction\n",
    "y = df_train['Survived'] # values to be predicted\n",
    "\n",
    "# split data from \"titanic_train_preprocessed.csv\" to training data (75%) and testing data (25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b7ce177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32) # cause of error: Failed to convert a NumPy array to a Tensor\n",
    "y_train = np.asarray(y_train).astype(np.float32) \n",
    "X_test = np.asarray(X_test).astype(np.float32) \n",
    "y_test = np.asarray(y_test).astype(np.float32) \n",
    "X = np.asarray(X).astype(np.float32)\n",
    "y = np.asarray(y).astype(np.float32)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(13,), activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "converted_data = pd.DataFrame(X_train)\n",
    "converted_data.to_csv('x_train_float32.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6427b49c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m     97\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "66824737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.asarray(y_pred).astype(np.int64)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7bd629fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5964125560538116\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "28bdb758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.8092\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8092\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8137\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8283\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8171\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8193\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8215\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8159\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8249\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7755\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8283\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8283\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8013\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8249\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8215\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8283\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8294\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8316\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8328\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8328\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8406\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8159\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8204\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8238\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8350\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8305\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8283\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8283\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8272\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8406\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8283\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8339\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8384\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8305\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8294\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8429\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8272\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8294\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8148\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8238\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8339\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8384\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8429\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8137\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8283\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8339\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8238\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8283\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8215\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8395\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8361\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8507\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8395\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8530\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8373\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8462\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8418\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8328\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8507\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8530\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8283\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8440\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8429\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8373\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8384\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8474\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8451\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8328\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8507\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8474\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8496\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8339\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8418\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8507\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8507\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8283\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8294\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8429\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8462\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8575\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8418\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8474\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8462\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8474\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8519\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8507\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8440\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8384\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8552\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8440\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8339\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8462\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8418\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8507\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8530\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8485\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8597\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8552\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1917ee77050>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once happy with the model accuracy, fit it on all data\n",
    "model.fit(X, y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "20d520e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId   Age  SibSp  Parch     Fare      2      3   male      Q  \\\n",
       "0          892  34.5      0      0   7.8292  False   True   True   True   \n",
       "1          893  47.0      1      0   7.0000  False   True  False  False   \n",
       "2          894  62.0      0      0   9.6875   True  False   True   True   \n",
       "3          895  27.0      0      0   8.6625  False   True   True  False   \n",
       "4          896  22.0      1      1  12.2875  False   True  False  False   \n",
       "\n",
       "       S   Miss     Mr    Mrs  \n",
       "0  False  False   True  False  \n",
       "1   True  False  False   True  \n",
       "2  False  False   True  False  \n",
       "3   True  False   True  False  \n",
       "4   True  False  False   True  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = pd.read_csv('titanic_test_preprocessed.csv')\n",
    "X_pred.replace([np.inf, -np.inf], np.nan, inplace=True) # becaouse of error NaN/inf\n",
    "X_pred.fillna(999, inplace=True) # becaouse of error NaN/inf\n",
    "X_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "40b5ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_convert = np.nan_to_num(X_pred) # conversion, otherwise y_pred throws an error\n",
    "X_pred_convert = np.asarray(X_pred_convert).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "967b908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03761048],\n",
       "       [0.25310695],\n",
       "       [0.06612486],\n",
       "       [0.03300935],\n",
       "       [0.4214758 ],\n",
       "       [0.08718682],\n",
       "       [0.5156815 ],\n",
       "       [0.09812428],\n",
       "       [0.88574284],\n",
       "       [0.03032201],\n",
       "       [0.03138824],\n",
       "       [0.13347219],\n",
       "       [0.99945766],\n",
       "       [0.08748962],\n",
       "       [0.9960982 ],\n",
       "       [0.9943686 ],\n",
       "       [0.1311424 ],\n",
       "       [0.0392967 ],\n",
       "       [0.2031857 ],\n",
       "       [0.5606372 ],\n",
       "       [0.57591796],\n",
       "       [0.70889336],\n",
       "       [0.9904896 ],\n",
       "       [0.6679197 ],\n",
       "       [0.9483659 ],\n",
       "       [0.02521634],\n",
       "       [0.9981485 ],\n",
       "       [0.03766945],\n",
       "       [0.19168214],\n",
       "       [0.03033537],\n",
       "       [0.08796033],\n",
       "       [0.09804881],\n",
       "       [0.31142125],\n",
       "       [0.4510208 ],\n",
       "       [0.4037061 ],\n",
       "       [0.04722293],\n",
       "       [0.3676448 ],\n",
       "       [0.5026451 ],\n",
       "       [0.03215994],\n",
       "       [0.33789167],\n",
       "       [0.03285532],\n",
       "       [0.18832904],\n",
       "       [0.02617314],\n",
       "       [0.9526111 ],\n",
       "       [0.9947277 ],\n",
       "       [0.02947315],\n",
       "       [0.22190702],\n",
       "       [0.03607908],\n",
       "       [0.99882746],\n",
       "       [0.38292307],\n",
       "       [0.35579637],\n",
       "       [0.15867734],\n",
       "       [0.81007504],\n",
       "       [0.9830019 ],\n",
       "       [0.1652095 ],\n",
       "       [0.11412336],\n",
       "       [0.02676913],\n",
       "       [0.0283403 ],\n",
       "       [0.02718874],\n",
       "       [0.9988164 ],\n",
       "       [0.05183015],\n",
       "       [0.08446976],\n",
       "       [0.04302164],\n",
       "       [0.5751107 ],\n",
       "       [0.99887645],\n",
       "       [0.9883757 ],\n",
       "       [0.7361528 ],\n",
       "       [0.36523938],\n",
       "       [0.26806596],\n",
       "       [0.9120442 ],\n",
       "       [0.5478878 ],\n",
       "       [0.03049686],\n",
       "       [0.35100716],\n",
       "       [0.26829025],\n",
       "       [0.9997429 ],\n",
       "       [0.93692935],\n",
       "       [0.0273023 ],\n",
       "       [0.69663477],\n",
       "       [0.08590146],\n",
       "       [0.5470515 ],\n",
       "       [0.8983094 ],\n",
       "       [0.80117744],\n",
       "       [0.11561535],\n",
       "       [0.02669153],\n",
       "       [0.1329311 ],\n",
       "       [0.02907197],\n",
       "       [0.5318449 ],\n",
       "       [0.71507066],\n",
       "       [0.52881896],\n",
       "       [0.99620795],\n",
       "       [0.63443226],\n",
       "       [0.02607584],\n",
       "       [0.9692228 ],\n",
       "       [0.02628872],\n",
       "       [0.25848716],\n",
       "       [0.02621748],\n",
       "       [0.99815017],\n",
       "       [0.02556268],\n",
       "       [0.6109672 ],\n",
       "       [0.02491902],\n",
       "       [0.997438  ],\n",
       "       [0.11951495],\n",
       "       [0.03363323],\n",
       "       [0.02555841],\n",
       "       [0.83808994],\n",
       "       [0.06381683],\n",
       "       [0.03869228],\n",
       "       [0.03349824],\n",
       "       [0.02620771],\n",
       "       [0.33819798],\n",
       "       [0.11061274],\n",
       "       [0.52712965],\n",
       "       [0.9756561 ],\n",
       "       [0.7422229 ],\n",
       "       [0.9996949 ],\n",
       "       [0.04014057],\n",
       "       [0.03048817],\n",
       "       [0.99019957],\n",
       "       [0.8115491 ],\n",
       "       [0.9722874 ],\n",
       "       [0.9977871 ],\n",
       "       [0.02030062],\n",
       "       [0.9975146 ],\n",
       "       [0.02354463],\n",
       "       [0.03304319],\n",
       "       [0.8751013 ],\n",
       "       [0.02880667],\n",
       "       [0.46769905],\n",
       "       [0.06086681],\n",
       "       [0.02621913],\n",
       "       [0.02340988],\n",
       "       [0.16729271],\n",
       "       [0.7118534 ],\n",
       "       [0.01807594],\n",
       "       [0.02101649],\n",
       "       [0.0258536 ],\n",
       "       [0.03148293],\n",
       "       [0.10822224],\n",
       "       [0.47736683],\n",
       "       [0.01690162],\n",
       "       [0.26259658],\n",
       "       [0.9997353 ],\n",
       "       [0.34638315],\n",
       "       [0.25383076],\n",
       "       [0.12410665],\n",
       "       [0.01032939],\n",
       "       [0.48730528],\n",
       "       [0.02930683],\n",
       "       [0.18278697],\n",
       "       [0.06441028],\n",
       "       [0.9999274 ],\n",
       "       [0.03172486],\n",
       "       [1.        ],\n",
       "       [0.2965101 ],\n",
       "       [0.08520467],\n",
       "       [0.02518609],\n",
       "       [0.9999457 ],\n",
       "       [0.49381495],\n",
       "       [0.12365837],\n",
       "       [0.63701034],\n",
       "       [0.5212139 ],\n",
       "       [0.90884227],\n",
       "       [0.9249122 ],\n",
       "       [0.02264661],\n",
       "       [0.06157678],\n",
       "       [0.6148256 ],\n",
       "       [0.55851185],\n",
       "       [0.03934102],\n",
       "       [0.990017  ],\n",
       "       [0.59869313],\n",
       "       [0.02310794],\n",
       "       [0.03025602],\n",
       "       [0.01957033],\n",
       "       [0.03021313],\n",
       "       [0.0112945 ],\n",
       "       [0.9992013 ],\n",
       "       [0.99918586],\n",
       "       [0.43671829],\n",
       "       [0.9759171 ],\n",
       "       [0.99733835],\n",
       "       [0.08392522],\n",
       "       [0.5271058 ],\n",
       "       [0.9990919 ],\n",
       "       [0.03150975],\n",
       "       [0.9999371 ],\n",
       "       [0.08085722],\n",
       "       [0.9889425 ],\n",
       "       [0.01210567],\n",
       "       [0.01643594],\n",
       "       [0.06285203],\n",
       "       [0.09828949],\n",
       "       [0.17401975],\n",
       "       [0.68770355],\n",
       "       [0.06853469],\n",
       "       [0.9985927 ],\n",
       "       [0.01997662],\n",
       "       [1.        ],\n",
       "       [0.8010142 ],\n",
       "       [0.16262662],\n",
       "       [0.64192027],\n",
       "       [0.67874366],\n",
       "       [0.9924884 ],\n",
       "       [0.8792068 ],\n",
       "       [0.9989501 ],\n",
       "       [0.11011939],\n",
       "       [0.23705216],\n",
       "       [0.46842286],\n",
       "       [0.13614021],\n",
       "       [0.9539803 ],\n",
       "       [0.0243135 ],\n",
       "       [0.0537182 ],\n",
       "       [0.0218304 ],\n",
       "       [0.99251   ],\n",
       "       [0.92383915],\n",
       "       [0.00909059],\n",
       "       [0.3624571 ],\n",
       "       [0.5198603 ],\n",
       "       [0.6790146 ],\n",
       "       [0.99953   ],\n",
       "       [0.02273346],\n",
       "       [0.75890285],\n",
       "       [0.03842025],\n",
       "       [0.9914055 ],\n",
       "       [0.03812946],\n",
       "       [0.97300595],\n",
       "       [0.760167  ],\n",
       "       [0.02811041],\n",
       "       [0.5194835 ],\n",
       "       [0.02453271],\n",
       "       [0.06933669],\n",
       "       [0.9940155 ],\n",
       "       [0.98419434],\n",
       "       [0.01495523],\n",
       "       [0.03095807],\n",
       "       [0.5820216 ],\n",
       "       [0.04951335],\n",
       "       [0.7337181 ],\n",
       "       [0.06467324],\n",
       "       [0.95137006],\n",
       "       [0.99965405],\n",
       "       [0.97223455],\n",
       "       [0.9409355 ],\n",
       "       [0.7657464 ],\n",
       "       [0.02212411],\n",
       "       [0.10056543],\n",
       "       [0.30058002],\n",
       "       [0.99821615],\n",
       "       [0.07765391],\n",
       "       [0.9783516 ],\n",
       "       [0.6461155 ],\n",
       "       [0.9997387 ],\n",
       "       [0.05282706],\n",
       "       [0.97389036],\n",
       "       [0.02811117],\n",
       "       [0.02081511],\n",
       "       [0.02156377],\n",
       "       [0.0303575 ],\n",
       "       [0.02153465],\n",
       "       [0.989627  ],\n",
       "       [0.04333521],\n",
       "       [0.01723504],\n",
       "       [0.04392198],\n",
       "       [0.9826404 ],\n",
       "       [0.9924432 ],\n",
       "       [0.1261284 ],\n",
       "       [0.02173992],\n",
       "       [0.02727463],\n",
       "       [0.02135405],\n",
       "       [0.3936655 ],\n",
       "       [0.11347881],\n",
       "       [0.84630215],\n",
       "       [0.03014124],\n",
       "       [0.9999805 ],\n",
       "       [0.48060644],\n",
       "       [0.02783965],\n",
       "       [0.9913282 ],\n",
       "       [0.0861876 ],\n",
       "       [0.08372197],\n",
       "       [0.07164612],\n",
       "       [0.26668662],\n",
       "       [0.65197533],\n",
       "       [0.97989213],\n",
       "       [0.5324961 ],\n",
       "       [0.97532564],\n",
       "       [0.99575186],\n",
       "       [0.01673152],\n",
       "       [0.02104426],\n",
       "       [0.80834234],\n",
       "       [0.02774004],\n",
       "       [0.02191938],\n",
       "       [0.4228098 ],\n",
       "       [0.47115946],\n",
       "       [0.02781227],\n",
       "       [0.4677957 ],\n",
       "       [0.0185295 ],\n",
       "       [0.02323035],\n",
       "       [0.99993056],\n",
       "       [0.01774048],\n",
       "       [0.4569427 ],\n",
       "       [0.02014454],\n",
       "       [0.01869848],\n",
       "       [0.21810482],\n",
       "       [0.06308818],\n",
       "       [0.03009741],\n",
       "       [0.53768975],\n",
       "       [0.6602929 ],\n",
       "       [0.98408854],\n",
       "       [0.9927746 ],\n",
       "       [0.5877751 ],\n",
       "       [0.3765982 ],\n",
       "       [0.10734951],\n",
       "       [0.05539035],\n",
       "       [0.02151231],\n",
       "       [0.44587737],\n",
       "       [0.9999005 ],\n",
       "       [0.9129018 ],\n",
       "       [0.886802  ],\n",
       "       [0.47936562],\n",
       "       [0.02184406],\n",
       "       [0.21127987],\n",
       "       [0.02321727],\n",
       "       [0.03315806],\n",
       "       [0.17339514],\n",
       "       [0.15226875],\n",
       "       [0.9999516 ],\n",
       "       [0.0339613 ],\n",
       "       [0.9981762 ],\n",
       "       [0.87569815],\n",
       "       [0.12143125],\n",
       "       [0.43156892],\n",
       "       [0.96975935],\n",
       "       [0.23006377],\n",
       "       [0.02853627],\n",
       "       [0.932198  ],\n",
       "       [0.02196664],\n",
       "       [0.15721269],\n",
       "       [0.08289623],\n",
       "       [0.00965577],\n",
       "       [0.64791447],\n",
       "       [0.22941993],\n",
       "       [0.5690557 ],\n",
       "       [0.01791603],\n",
       "       [0.05812999],\n",
       "       [0.9920775 ],\n",
       "       [0.08434027],\n",
       "       [0.92853636],\n",
       "       [0.18997386],\n",
       "       [0.5664944 ],\n",
       "       [0.29135564],\n",
       "       [0.95377547],\n",
       "       [0.9985778 ],\n",
       "       [0.19324951],\n",
       "       [0.9956553 ],\n",
       "       [0.24496017],\n",
       "       [0.9976735 ],\n",
       "       [0.09114409],\n",
       "       [0.9767895 ],\n",
       "       [0.02205943],\n",
       "       [0.02891605],\n",
       "       [0.5448921 ],\n",
       "       [0.01324493],\n",
       "       [0.9991319 ],\n",
       "       [0.98920625],\n",
       "       [0.0229717 ],\n",
       "       [0.99916124],\n",
       "       [0.9076767 ],\n",
       "       [0.02011586],\n",
       "       [0.99127495],\n",
       "       [0.9979758 ],\n",
       "       [0.17382288],\n",
       "       [0.17432283],\n",
       "       [0.99997985],\n",
       "       [0.01361418],\n",
       "       [0.0534905 ],\n",
       "       [0.9982228 ],\n",
       "       [0.99997044],\n",
       "       [0.22424835],\n",
       "       [0.44917277],\n",
       "       [0.42635402],\n",
       "       [0.64368993],\n",
       "       [0.02882175],\n",
       "       [0.03130244],\n",
       "       [0.86872303],\n",
       "       [0.94096863],\n",
       "       [0.17698415],\n",
       "       [0.99891067],\n",
       "       [0.03628046],\n",
       "       [0.03934911],\n",
       "       [0.07131846],\n",
       "       [0.7307287 ],\n",
       "       [0.98655444],\n",
       "       [0.9730393 ],\n",
       "       [0.95597476],\n",
       "       [0.03958539],\n",
       "       [0.00554578],\n",
       "       [0.99979264],\n",
       "       [0.03791809],\n",
       "       [0.99859744],\n",
       "       [0.05856341],\n",
       "       [0.02535427],\n",
       "       [0.9999893 ],\n",
       "       [0.05537912],\n",
       "       [0.9994848 ],\n",
       "       [0.93828535],\n",
       "       [0.08506777],\n",
       "       [0.6946915 ],\n",
       "       [0.12019574],\n",
       "       [0.92008793],\n",
       "       [0.59422094],\n",
       "       [0.9946009 ],\n",
       "       [0.5970756 ],\n",
       "       [0.9998417 ],\n",
       "       [0.4729487 ],\n",
       "       [0.02318241],\n",
       "       [0.9999714 ],\n",
       "       [0.01411049],\n",
       "       [0.02338016],\n",
       "       [0.29050508]], dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all = model.predict(X_pred_convert)\n",
    "y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c1687ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all = np.where(y_pred <= 0.5, 0, 1) # convert float numbers between 0 and 1 to only 0 or 1\n",
    "y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0b1c7e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892       0.0\n",
       "1            893       0.0\n",
       "2            894       0.0\n",
       "3            895       0.0\n",
       "4            896       0.0\n",
       "..           ...       ...\n",
       "413         1305       NaN\n",
       "414         1306       NaN\n",
       "415         1307       NaN\n",
       "416         1308       NaN\n",
       "417         1309       NaN\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert numpy ndarray back to dataframe\n",
    "#predicted_data = pd.DataFrame(y_pred_all)\n",
    "\n",
    "# append the predicted data to final file\n",
    "df_test = pd.read_csv('titanic_test_preprocessed.csv')\n",
    "df_test = pd.concat([df_test,predicted_data],axis=1) # append predicted y\n",
    "df_test = df_test.rename(columns = {0:'Survived'}) # rename added column\n",
    "df_test = df_test[['PassengerId', 'Survived']] # leave only requested columns for submit\n",
    "df_test # check if correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff26c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "df_test.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
