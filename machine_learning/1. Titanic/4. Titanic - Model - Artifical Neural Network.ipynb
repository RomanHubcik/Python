{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08b1758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2abba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed train dataset\n",
    "df_train = pd.read_csv('titanic_train_preprocessed.csv')\n",
    "\n",
    "# create matrix of the features (X) and target (y)\n",
    "X = df_train.drop('Survived',axis=1) # values used for prediction\n",
    "y = df_train['Survived'] # values to be predicted\n",
    "\n",
    "# split data from \"titanic_train_preprocessed.csv\" to training data (80%) and testing data (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ce177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 6ms/step - loss: 0.4787 - accuracy: 0.7733 - val_loss: 0.3979 - val_accuracy: 0.8322\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8383 - val_loss: 0.4221 - val_accuracy: 0.8252\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8436 - val_loss: 0.3963 - val_accuracy: 0.8392\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8401 - val_loss: 0.3878 - val_accuracy: 0.8462\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8594 - val_loss: 0.4230 - val_accuracy: 0.8252\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8489 - val_loss: 0.4378 - val_accuracy: 0.8392\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8489 - val_loss: 0.4019 - val_accuracy: 0.8392\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8541 - val_loss: 0.4184 - val_accuracy: 0.8322\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8541 - val_loss: 0.4480 - val_accuracy: 0.7902\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8647 - val_loss: 0.4288 - val_accuracy: 0.8252\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8647 - val_loss: 0.4353 - val_accuracy: 0.8322\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8647 - val_loss: 0.4915 - val_accuracy: 0.8182\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8664 - val_loss: 0.4615 - val_accuracy: 0.8252\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8735 - val_loss: 0.4482 - val_accuracy: 0.8322\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8682 - val_loss: 0.4610 - val_accuracy: 0.8182\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8770 - val_loss: 0.4721 - val_accuracy: 0.8182\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.8770 - val_loss: 0.4771 - val_accuracy: 0.8322\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8699 - val_loss: 0.4613 - val_accuracy: 0.8392\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8840 - val_loss: 0.4879 - val_accuracy: 0.8252\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2871 - accuracy: 0.8893 - val_loss: 0.4848 - val_accuracy: 0.8252\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.8735 - val_loss: 0.4895 - val_accuracy: 0.8042\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.8875 - val_loss: 0.4906 - val_accuracy: 0.8042\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2866 - accuracy: 0.8787 - val_loss: 0.5452 - val_accuracy: 0.8182\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8805 - val_loss: 0.5567 - val_accuracy: 0.8112\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8805 - val_loss: 0.5791 - val_accuracy: 0.8322\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.8822 - val_loss: 0.5083 - val_accuracy: 0.8112\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2703 - accuracy: 0.8875 - val_loss: 0.5533 - val_accuracy: 0.8112\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.8805 - val_loss: 0.5895 - val_accuracy: 0.8112\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8893 - val_loss: 0.5825 - val_accuracy: 0.8112\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8770 - val_loss: 0.6381 - val_accuracy: 0.8182\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2652 - accuracy: 0.8981 - val_loss: 0.5660 - val_accuracy: 0.8112\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.8928 - val_loss: 0.5697 - val_accuracy: 0.8182\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.8858 - val_loss: 0.5839 - val_accuracy: 0.8112\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.8858 - val_loss: 0.5777 - val_accuracy: 0.8182\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8910 - val_loss: 0.6344 - val_accuracy: 0.7972\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2540 - accuracy: 0.8928 - val_loss: 0.6787 - val_accuracy: 0.8112\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.8805 - val_loss: 0.6266 - val_accuracy: 0.8112\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.8893 - val_loss: 0.5903 - val_accuracy: 0.7972\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.8858 - val_loss: 0.6669 - val_accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.8875 - val_loss: 0.6500 - val_accuracy: 0.7972\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.8893 - val_loss: 0.6333 - val_accuracy: 0.8112\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2551 - accuracy: 0.8910 - val_loss: 0.6228 - val_accuracy: 0.8112\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.2530 - accuracy: 0.8875 - val_loss: 0.6106 - val_accuracy: 0.8112\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.2421 - accuracy: 0.8946 - val_loss: 0.6399 - val_accuracy: 0.7972\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.8928 - val_loss: 0.6288 - val_accuracy: 0.8112\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.8910 - val_loss: 0.6561 - val_accuracy: 0.8112\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.8963 - val_loss: 0.5940 - val_accuracy: 0.8042\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.8893 - val_loss: 0.6440 - val_accuracy: 0.8182\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.8910 - val_loss: 0.6622 - val_accuracy: 0.7972\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.8946 - val_loss: 0.6958 - val_accuracy: 0.8392\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.8963 - val_loss: 0.6268 - val_accuracy: 0.8182\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.8910 - val_loss: 0.6532 - val_accuracy: 0.8252\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.2362 - accuracy: 0.8963 - val_loss: 0.6537 - val_accuracy: 0.8462\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.8981 - val_loss: 0.6650 - val_accuracy: 0.8182\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.8910 - val_loss: 0.6597 - val_accuracy: 0.8112\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.8998 - val_loss: 0.7169 - val_accuracy: 0.7972\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9033 - val_loss: 0.6987 - val_accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.8928 - val_loss: 0.7096 - val_accuracy: 0.7902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.8981 - val_loss: 0.7207 - val_accuracy: 0.8112\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.8946 - val_loss: 0.6628 - val_accuracy: 0.8112\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9016 - val_loss: 0.6951 - val_accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9016 - val_loss: 0.7311 - val_accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.8981 - val_loss: 0.8168 - val_accuracy: 0.8252\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.9069 - val_loss: 0.7003 - val_accuracy: 0.8112\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2231 - accuracy: 0.9016 - val_loss: 0.7506 - val_accuracy: 0.8042\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2225 - accuracy: 0.8963 - val_loss: 0.7062 - val_accuracy: 0.8042\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2228 - accuracy: 0.9016 - val_loss: 0.7605 - val_accuracy: 0.8042\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.8998 - val_loss: 0.7726 - val_accuracy: 0.7972\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2163 - accuracy: 0.9033 - val_loss: 0.7239 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2163 - accuracy: 0.9016 - val_loss: 0.7972 - val_accuracy: 0.8322\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9051 - val_loss: 0.7117 - val_accuracy: 0.8112\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9086 - val_loss: 0.7803 - val_accuracy: 0.8042\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9016 - val_loss: 0.7921 - val_accuracy: 0.8182\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.8998 - val_loss: 0.8051 - val_accuracy: 0.8042\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.8963 - val_loss: 0.7559 - val_accuracy: 0.8182\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9086 - val_loss: 0.7496 - val_accuracy: 0.8182\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.8998 - val_loss: 0.7646 - val_accuracy: 0.8252\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9016 - val_loss: 0.7812 - val_accuracy: 0.8182\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9016 - val_loss: 0.8223 - val_accuracy: 0.8042\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9033 - val_loss: 0.8108 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9051 - val_loss: 0.7810 - val_accuracy: 0.8112\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.8946 - val_loss: 0.7744 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2020 - accuracy: 0.9033 - val_loss: 0.8084 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.2031 - accuracy: 0.9069 - val_loss: 0.7914 - val_accuracy: 0.8112\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.9069 - val_loss: 0.8137 - val_accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.8963 - val_loss: 0.8612 - val_accuracy: 0.7972\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2020 - accuracy: 0.9104 - val_loss: 0.8227 - val_accuracy: 0.8252\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.8981 - val_loss: 0.8907 - val_accuracy: 0.8112\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9086 - val_loss: 0.8660 - val_accuracy: 0.8042\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.9121 - val_loss: 0.8320 - val_accuracy: 0.8112\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2048 - accuracy: 0.9051 - val_loss: 0.8380 - val_accuracy: 0.7972\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.9121 - val_loss: 0.8607 - val_accuracy: 0.8252\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9104 - val_loss: 0.8498 - val_accuracy: 0.7972\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.9139 - val_loss: 0.8866 - val_accuracy: 0.8112\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9121 - val_loss: 0.8797 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9069 - val_loss: 0.8844 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9051 - val_loss: 0.8547 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9139 - val_loss: 0.8614 - val_accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1897 - accuracy: 0.9139 - val_loss: 0.9081 - val_accuracy: 0.7972\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9174 - val_loss: 0.9118 - val_accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(27,), activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "training = model.fit(X_train, y_train, epochs=100, batch_size=8, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd629fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val_acc: 88.94%\n"
     ]
    }
   ],
   "source": [
    "val_acc = np.mean(training.history['accuracy'])\n",
    "print(\"\\n%s: %.2f%%\" % ('val_acc', val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28bdb758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1757 - accuracy: 0.9284 - val_loss: 0.3936 - val_accuracy: 0.8771\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1740 - accuracy: 0.9270 - val_loss: 0.4167 - val_accuracy: 0.8771\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9312 - val_loss: 0.4253 - val_accuracy: 0.8771\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9256 - val_loss: 0.3908 - val_accuracy: 0.8827\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9270 - val_loss: 0.3806 - val_accuracy: 0.8827\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9298 - val_loss: 0.3957 - val_accuracy: 0.8771\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9284 - val_loss: 0.3964 - val_accuracy: 0.8771\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9270 - val_loss: 0.4168 - val_accuracy: 0.8771\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9354 - val_loss: 0.3977 - val_accuracy: 0.8715\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9228 - val_loss: 0.3875 - val_accuracy: 0.8659\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9326 - val_loss: 0.3968 - val_accuracy: 0.8827\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9298 - val_loss: 0.3991 - val_accuracy: 0.8715\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9326 - val_loss: 0.4074 - val_accuracy: 0.8659\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1657 - accuracy: 0.9298 - val_loss: 0.3980 - val_accuracy: 0.8715\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9340 - val_loss: 0.4377 - val_accuracy: 0.8883\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1617 - accuracy: 0.9270 - val_loss: 0.3976 - val_accuracy: 0.8771\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9312 - val_loss: 0.4484 - val_accuracy: 0.8883\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9340 - val_loss: 0.4536 - val_accuracy: 0.8659\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9228 - val_loss: 0.4029 - val_accuracy: 0.8827\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9312 - val_loss: 0.4359 - val_accuracy: 0.8827\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1736 - accuracy: 0.9298 - val_loss: 0.4783 - val_accuracy: 0.8827\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9256 - val_loss: 0.6630 - val_accuracy: 0.8827\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1904 - accuracy: 0.9199 - val_loss: 0.4138 - val_accuracy: 0.8939\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.9270 - val_loss: 0.3850 - val_accuracy: 0.8939\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.9185 - val_loss: 0.4036 - val_accuracy: 0.8827\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9242 - val_loss: 0.3782 - val_accuracy: 0.8771\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9410 - val_loss: 0.3930 - val_accuracy: 0.8659\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1581 - accuracy: 0.9354 - val_loss: 0.4107 - val_accuracy: 0.8827\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9438 - val_loss: 0.4031 - val_accuracy: 0.8771\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9396 - val_loss: 0.4268 - val_accuracy: 0.8771\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9410 - val_loss: 0.4211 - val_accuracy: 0.8827\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9396 - val_loss: 0.4178 - val_accuracy: 0.8771\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9382 - val_loss: 0.4101 - val_accuracy: 0.8827\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9354 - val_loss: 0.3989 - val_accuracy: 0.8827\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9340 - val_loss: 0.4658 - val_accuracy: 0.8715\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1564 - accuracy: 0.9354 - val_loss: 0.3971 - val_accuracy: 0.8827\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9368 - val_loss: 0.4345 - val_accuracy: 0.8771\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9340 - val_loss: 0.4203 - val_accuracy: 0.8771\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9382 - val_loss: 0.4227 - val_accuracy: 0.8771\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9424 - val_loss: 0.4467 - val_accuracy: 0.8715\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9312 - val_loss: 0.4199 - val_accuracy: 0.8827\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9396 - val_loss: 0.4296 - val_accuracy: 0.8659\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9396 - val_loss: 0.4150 - val_accuracy: 0.8827\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9340 - val_loss: 0.4337 - val_accuracy: 0.8827\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 0.9326 - val_loss: 0.4056 - val_accuracy: 0.8771\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1533 - accuracy: 0.9354 - val_loss: 0.4292 - val_accuracy: 0.8715\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9340 - val_loss: 0.4476 - val_accuracy: 0.8771\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9410 - val_loss: 0.4367 - val_accuracy: 0.8771\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9382 - val_loss: 0.4406 - val_accuracy: 0.8771\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9368 - val_loss: 0.4809 - val_accuracy: 0.8771\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9312 - val_loss: 0.4559 - val_accuracy: 0.8771\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9326 - val_loss: 0.4407 - val_accuracy: 0.8771\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9340 - val_loss: 0.4849 - val_accuracy: 0.8715\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9368 - val_loss: 0.4708 - val_accuracy: 0.8771\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9298 - val_loss: 0.4677 - val_accuracy: 0.8659\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9368 - val_loss: 0.4952 - val_accuracy: 0.8659\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9368 - val_loss: 0.4264 - val_accuracy: 0.8771\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9424 - val_loss: 0.4681 - val_accuracy: 0.8659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 0.9354 - val_loss: 0.4391 - val_accuracy: 0.8827\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9354 - val_loss: 0.4708 - val_accuracy: 0.8771\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9340 - val_loss: 0.4770 - val_accuracy: 0.8659\n",
      "Epoch 62/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1503 - accuracy: 0.9340 - val_loss: 0.4748 - val_accuracy: 0.8771\n",
      "Epoch 63/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9396 - val_loss: 0.4723 - val_accuracy: 0.8715\n",
      "Epoch 64/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9326 - val_loss: 0.4457 - val_accuracy: 0.8715\n",
      "Epoch 65/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9354 - val_loss: 0.4874 - val_accuracy: 0.8715\n",
      "Epoch 66/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9326 - val_loss: 0.4383 - val_accuracy: 0.8827\n",
      "Epoch 67/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9382 - val_loss: 0.4590 - val_accuracy: 0.8827\n",
      "Epoch 68/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9396 - val_loss: 0.4942 - val_accuracy: 0.8715\n",
      "Epoch 69/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9368 - val_loss: 0.4496 - val_accuracy: 0.8771\n",
      "Epoch 70/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9354 - val_loss: 0.4871 - val_accuracy: 0.8715\n",
      "Epoch 71/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9424 - val_loss: 0.5220 - val_accuracy: 0.8771\n",
      "Epoch 72/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9354 - val_loss: 0.4690 - val_accuracy: 0.8715\n",
      "Epoch 73/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9368 - val_loss: 0.4743 - val_accuracy: 0.8715\n",
      "Epoch 74/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9410 - val_loss: 0.4997 - val_accuracy: 0.8715\n",
      "Epoch 75/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9354 - val_loss: 0.4810 - val_accuracy: 0.8715\n",
      "Epoch 76/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9326 - val_loss: 0.4971 - val_accuracy: 0.8827\n",
      "Epoch 77/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9382 - val_loss: 0.4881 - val_accuracy: 0.8715\n",
      "Epoch 78/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9410 - val_loss: 0.5158 - val_accuracy: 0.8715\n",
      "Epoch 79/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9340 - val_loss: 0.5080 - val_accuracy: 0.8715\n",
      "Epoch 80/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.9087 - val_loss: 0.7509 - val_accuracy: 0.8883\n",
      "Epoch 81/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.2106 - accuracy: 0.9129 - val_loss: 0.4531 - val_accuracy: 0.8883\n",
      "Epoch 82/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9213 - val_loss: 0.4509 - val_accuracy: 0.8883\n",
      "Epoch 83/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9340 - val_loss: 0.4176 - val_accuracy: 0.8883\n",
      "Epoch 84/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9382 - val_loss: 0.4181 - val_accuracy: 0.8939\n",
      "Epoch 85/100\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9396 - val_loss: 0.4388 - val_accuracy: 0.8883\n",
      "Epoch 86/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9452 - val_loss: 0.4488 - val_accuracy: 0.8827\n",
      "Epoch 87/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9410 - val_loss: 0.4677 - val_accuracy: 0.8827\n",
      "Epoch 88/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9494 - val_loss: 0.4634 - val_accuracy: 0.8827\n",
      "Epoch 89/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9410 - val_loss: 0.4746 - val_accuracy: 0.8827\n",
      "Epoch 90/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9438 - val_loss: 0.4680 - val_accuracy: 0.8827\n",
      "Epoch 91/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9410 - val_loss: 0.4662 - val_accuracy: 0.8883\n",
      "Epoch 92/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9424 - val_loss: 0.4686 - val_accuracy: 0.8939\n",
      "Epoch 93/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9452 - val_loss: 0.4877 - val_accuracy: 0.8883\n",
      "Epoch 94/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9452 - val_loss: 0.4802 - val_accuracy: 0.8883\n",
      "Epoch 95/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9438 - val_loss: 0.4810 - val_accuracy: 0.8771\n",
      "Epoch 96/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9410 - val_loss: 0.4816 - val_accuracy: 0.8939\n",
      "Epoch 97/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9438 - val_loss: 0.4914 - val_accuracy: 0.8827\n",
      "Epoch 98/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9382 - val_loss: 0.4851 - val_accuracy: 0.8827\n",
      "Epoch 99/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9452 - val_loss: 0.4945 - val_accuracy: 0.8883\n",
      "Epoch 100/100\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9438 - val_loss: 0.4974 - val_accuracy: 0.8771\n"
     ]
    }
   ],
   "source": [
    "# once happy with the model accuracy, fit it on all data\n",
    "history = model.fit(X, y, epochs=100, batch_size=8, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dd4aa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51576f26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mclf()   \u001b[38;5;66;03m# clear figure\u001b[39;00m\n\u001b[0;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, \u001b[43maccuracy\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbo\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining acc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, val_accuracy, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation acc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining and validation accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#neural network result\n",
    "import matplotlib.pyplot as plt\n",
    "plt.clf()   # clear figure\n",
    "\n",
    "epochs = 100\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20d520e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "      <th>EmbarkC</th>\n",
       "      <th>EmbarkQ</th>\n",
       "      <th>EmbarkS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.452723</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.776231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287881</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.361843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.396975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.512066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.505473</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.396975</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.396975</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.498966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  SibSp     Parch      Fare  Relatives  Age_Class  Female  Male  \\\n",
       "0    0.452723  0.000  0.000000  0.015282        0.0   0.569037     0.0   1.0   \n",
       "1    0.617566  0.125  0.000000  0.013663        0.1   0.776231     1.0   0.0   \n",
       "2    0.815377  0.000  0.000000  0.018909        0.0   0.682303     0.0   1.0   \n",
       "3    0.353818  0.000  0.000000  0.016908        0.0   0.444721     0.0   1.0   \n",
       "4    0.287881  0.125  0.111111  0.023984        0.2   0.361843     1.0   0.0   \n",
       "..        ...    ...       ...       ...        ...        ...     ...   ...   \n",
       "413  0.396975  0.000  0.000000  0.015713        0.0   0.498966     0.0   1.0   \n",
       "414  0.512066  0.000  0.000000  0.212559        0.0   0.212664     1.0   0.0   \n",
       "415  0.505473  0.000  0.000000  0.014151        0.0   0.635339     0.0   1.0   \n",
       "416  0.396975  0.000  0.000000  0.015713        0.0   0.498966     0.0   1.0   \n",
       "417  0.396975  0.125  0.111111  0.043640        0.2   0.498966     0.0   1.0   \n",
       "\n",
       "     Master  Miss   Mr  Mrs  Class 1  Class 2  Class 3  EmbarkC  EmbarkQ  \\\n",
       "0       0.0   0.0  1.0  0.0      0.0      0.0      1.0      0.0      1.0   \n",
       "1       0.0   0.0  0.0  1.0      0.0      0.0      1.0      0.0      0.0   \n",
       "2       0.0   0.0  1.0  0.0      0.0      1.0      0.0      0.0      1.0   \n",
       "3       0.0   0.0  1.0  0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "4       0.0   0.0  0.0  1.0      0.0      0.0      1.0      0.0      0.0   \n",
       "..      ...   ...  ...  ...      ...      ...      ...      ...      ...   \n",
       "413     0.0   0.0  1.0  0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "414     0.0   0.0  0.0  1.0      1.0      0.0      0.0      1.0      0.0   \n",
       "415     0.0   0.0  1.0  0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "416     0.0   0.0  1.0  0.0      0.0      0.0      1.0      0.0      0.0   \n",
       "417     1.0   0.0  0.0  0.0      0.0      0.0      1.0      1.0      0.0   \n",
       "\n",
       "     EmbarkS  \n",
       "0        0.0  \n",
       "1        1.0  \n",
       "2        0.0  \n",
       "3        1.0  \n",
       "4        1.0  \n",
       "..       ...  \n",
       "413      1.0  \n",
       "414      0.0  \n",
       "415      1.0  \n",
       "416      1.0  \n",
       "417      0.0  \n",
       "\n",
       "[418 rows x 18 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = pd.read_csv('titanic_test_preprocessed2.csv')\n",
    "X_pred.replace([np.inf, -np.inf], np.nan, inplace=True) # becaouse of error NaN/inf\n",
    "X_pred.fillna(999, inplace=True) # becaouse of error NaN/inf\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40b5ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pred_convert = np.nan_to_num(X_pred) # conversion, otherwise y_pred throws an error\n",
    "# X_pred_convert = np.asarray(X_pred_convert).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "967b908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01179855],\n",
       "       [0.00008629],\n",
       "       [0.00003242],\n",
       "       [0.13591999],\n",
       "       [0.39025643],\n",
       "       [0.09952015],\n",
       "       [0.7389188 ],\n",
       "       [0.0018392 ],\n",
       "       [0.99889845],\n",
       "       [0.00044949],\n",
       "       [0.14825407],\n",
       "       [0.28266147],\n",
       "       [0.9998101 ],\n",
       "       [0.00000269],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.0000478 ],\n",
       "       [0.2678329 ],\n",
       "       [0.0080446 ],\n",
       "       [0.00000037],\n",
       "       [0.8367143 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.799165  ],\n",
       "       [1.        ],\n",
       "       [0.00000173],\n",
       "       [0.99999875],\n",
       "       [0.2227307 ],\n",
       "       [0.3449966 ],\n",
       "       [0.00022825],\n",
       "       [0.00025041],\n",
       "       [0.00055765],\n",
       "       [0.80887   ],\n",
       "       [0.83556557],\n",
       "       [0.76579666],\n",
       "       [0.26309708],\n",
       "       [0.03097962],\n",
       "       [0.5838375 ],\n",
       "       [0.12875561],\n",
       "       [0.8195945 ],\n",
       "       [0.00034812],\n",
       "       [0.5629454 ],\n",
       "       [0.06573266],\n",
       "       [0.9989218 ],\n",
       "       [1.        ],\n",
       "       [0.12482071],\n",
       "       [0.34316325],\n",
       "       [0.04125755],\n",
       "       [1.        ],\n",
       "       [0.09629517],\n",
       "       [0.24149461],\n",
       "       [0.34298426],\n",
       "       [0.99997324],\n",
       "       [1.        ],\n",
       "       [0.27212888],\n",
       "       [0.00000001],\n",
       "       [0.17151748],\n",
       "       [0.12420167],\n",
       "       [0.00276236],\n",
       "       [1.        ],\n",
       "       [0.0994273 ],\n",
       "       [0.1334764 ],\n",
       "       [0.10138039],\n",
       "       [0.72563285],\n",
       "       [0.99999994],\n",
       "       [0.9993648 ],\n",
       "       [0.6895369 ],\n",
       "       [0.07996209],\n",
       "       [0.4015814 ],\n",
       "       [1.        ],\n",
       "       [0.74550277],\n",
       "       [0.11103491],\n",
       "       [0.07007381],\n",
       "       [0.37101835],\n",
       "       [1.        ],\n",
       "       [0.00000138],\n",
       "       [0.14873789],\n",
       "       [1.        ],\n",
       "       [0.1297359 ],\n",
       "       [0.74550277],\n",
       "       [1.        ],\n",
       "       [0.9988483 ],\n",
       "       [0.21430862],\n",
       "       [0.14825407],\n",
       "       [0.00009885],\n",
       "       [0.00034462],\n",
       "       [0.7705286 ],\n",
       "       [0.6227128 ],\n",
       "       [0.72684216],\n",
       "       [1.        ],\n",
       "       [0.45868567],\n",
       "       [0.14787596],\n",
       "       [0.41411608],\n",
       "       [0.14873789],\n",
       "       [0.3072949 ],\n",
       "       [0.12452956],\n",
       "       [1.        ],\n",
       "       [0.14283395],\n",
       "       [0.60613704],\n",
       "       [0.16135006],\n",
       "       [1.        ],\n",
       "       [0.2160715 ],\n",
       "       [0.04125755],\n",
       "       [0.12868765],\n",
       "       [0.45467353],\n",
       "       [0.22019824],\n",
       "       [0.05667093],\n",
       "       [0.04125755],\n",
       "       [0.15083139],\n",
       "       [0.1031933 ],\n",
       "       [0.00803929],\n",
       "       [0.726817  ],\n",
       "       [0.01334747],\n",
       "       [0.6919623 ],\n",
       "       [1.        ],\n",
       "       [0.2159797 ],\n",
       "       [0.00419753],\n",
       "       [0.90068096],\n",
       "       [0.16560847],\n",
       "       [0.8683942 ],\n",
       "       [0.9298572 ],\n",
       "       [0.00162062],\n",
       "       [1.        ],\n",
       "       [0.13672416],\n",
       "       [0.04125755],\n",
       "       [0.44857386],\n",
       "       [0.11430737],\n",
       "       [0.9999781 ],\n",
       "       [0.12787727],\n",
       "       [0.1218907 ],\n",
       "       [0.1563004 ],\n",
       "       [0.22116278],\n",
       "       [0.08872893],\n",
       "       [0.00028339],\n",
       "       [0.01323733],\n",
       "       [0.12145901],\n",
       "       [0.07577117],\n",
       "       [0.11753929],\n",
       "       [0.5093645 ],\n",
       "       [0.        ],\n",
       "       [0.02197452],\n",
       "       [1.        ],\n",
       "       [0.00002883],\n",
       "       [0.1308057 ],\n",
       "       [0.36539578],\n",
       "       [0.00000165],\n",
       "       [0.18574595],\n",
       "       [0.11481347],\n",
       "       [0.5629454 ],\n",
       "       [0.00109412],\n",
       "       [1.        ],\n",
       "       [0.00414304],\n",
       "       [0.00000002],\n",
       "       [0.11224684],\n",
       "       [0.00003447],\n",
       "       [0.12079093],\n",
       "       [1.        ],\n",
       "       [0.50912446],\n",
       "       [0.36539578],\n",
       "       [0.50295603],\n",
       "       [0.7268565 ],\n",
       "       [1.        ],\n",
       "       [0.8008281 ],\n",
       "       [0.14546908],\n",
       "       [0.12917896],\n",
       "       [0.60455316],\n",
       "       [0.19908533],\n",
       "       [0.00012032],\n",
       "       [1.        ],\n",
       "       [0.55464774],\n",
       "       [0.14717382],\n",
       "       [0.05076542],\n",
       "       [0.07987269],\n",
       "       [0.00416792],\n",
       "       [0.00000003],\n",
       "       [0.9999672 ],\n",
       "       [0.8395702 ],\n",
       "       [0.89035875],\n",
       "       [0.99998236],\n",
       "       [1.        ],\n",
       "       [0.1297359 ],\n",
       "       [0.27307448],\n",
       "       [0.95520884],\n",
       "       [0.04125755],\n",
       "       [1.        ],\n",
       "       [0.13203394],\n",
       "       [0.84727   ],\n",
       "       [0.00141194],\n",
       "       [0.00001357],\n",
       "       [0.13049187],\n",
       "       [0.12205607],\n",
       "       [0.56235754],\n",
       "       [0.9995169 ],\n",
       "       [0.00002606],\n",
       "       [1.        ],\n",
       "       [0.16056035],\n",
       "       [1.        ],\n",
       "       [0.6225176 ],\n",
       "       [0.10544239],\n",
       "       [0.26738974],\n",
       "       [0.71968913],\n",
       "       [1.        ],\n",
       "       [0.00755889],\n",
       "       [0.9999788 ],\n",
       "       [0.11107269],\n",
       "       [0.38510972],\n",
       "       [0.38158786],\n",
       "       [0.10764145],\n",
       "       [0.08557431],\n",
       "       [0.12475486],\n",
       "       [0.27040038],\n",
       "       [0.14562337],\n",
       "       [0.01044127],\n",
       "       [1.        ],\n",
       "       [0.13585524],\n",
       "       [0.18878452],\n",
       "       [0.72673106],\n",
       "       [0.13383336],\n",
       "       [1.        ],\n",
       "       [0.14873789],\n",
       "       [1.        ],\n",
       "       [0.11133376],\n",
       "       [0.9645762 ],\n",
       "       [0.11084151],\n",
       "       [1.        ],\n",
       "       [0.15203826],\n",
       "       [0.11800548],\n",
       "       [0.72684216],\n",
       "       [0.06547263],\n",
       "       [0.13427769],\n",
       "       [0.01546445],\n",
       "       [0.9994312 ],\n",
       "       [0.22918884],\n",
       "       [0.04108106],\n",
       "       [0.75031656],\n",
       "       [0.10761042],\n",
       "       [0.14549749],\n",
       "       [0.27423674],\n",
       "       [0.9942525 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.00074026],\n",
       "       [0.1482281 ],\n",
       "       [0.01471582],\n",
       "       [0.22973542],\n",
       "       [0.9708466 ],\n",
       "       [0.00002628],\n",
       "       [0.8683942 ],\n",
       "       [0.00018022],\n",
       "       [1.        ],\n",
       "       [0.10774381],\n",
       "       [0.00058441],\n",
       "       [0.12473425],\n",
       "       [0.16441897],\n",
       "       [0.1471738 ],\n",
       "       [0.04125755],\n",
       "       [0.13903691],\n",
       "       [0.832107  ],\n",
       "       [0.11080127],\n",
       "       [0.00023545],\n",
       "       [0.1109544 ],\n",
       "       [0.97335607],\n",
       "       [0.903062  ],\n",
       "       [0.2980311 ],\n",
       "       [0.14825407],\n",
       "       [0.4123654 ],\n",
       "       [0.14717382],\n",
       "       [0.03097962],\n",
       "       [0.10061952],\n",
       "       [0.03375023],\n",
       "       [0.04125755],\n",
       "       [1.        ],\n",
       "       [0.97638685],\n",
       "       [0.00416808],\n",
       "       [0.81746465],\n",
       "       [0.12175619],\n",
       "       [0.01595473],\n",
       "       [0.20793827],\n",
       "       [0.10370966],\n",
       "       [0.51011515],\n",
       "       [0.99999684],\n",
       "       [0.72684216],\n",
       "       [0.9090439 ],\n",
       "       [0.8786815 ],\n",
       "       [0.17441808],\n",
       "       [0.14624192],\n",
       "       [0.15597667],\n",
       "       [0.00416792],\n",
       "       [0.14873789],\n",
       "       [0.38101786],\n",
       "       [0.73949915],\n",
       "       [0.00416792],\n",
       "       [0.00941227],\n",
       "       [0.18495728],\n",
       "       [0.12901531],\n",
       "       [1.        ],\n",
       "       [0.00022825],\n",
       "       [0.27408195],\n",
       "       [0.1426192 ],\n",
       "       [0.15541662],\n",
       "       [0.2762466 ],\n",
       "       [0.03072112],\n",
       "       [0.12324968],\n",
       "       [0.72684216],\n",
       "       [1.        ],\n",
       "       [0.14907733],\n",
       "       [1.        ],\n",
       "       [0.02152892],\n",
       "       [0.00019551],\n",
       "       [0.10299464],\n",
       "       [0.24480334],\n",
       "       [0.14725171],\n",
       "       [0.20416465],\n",
       "       [1.        ],\n",
       "       [0.6871622 ],\n",
       "       [0.00165447],\n",
       "       [0.10111382],\n",
       "       [0.13361475],\n",
       "       [0.00079247],\n",
       "       [0.12868765],\n",
       "       [0.13180202],\n",
       "       [0.11753929],\n",
       "       [0.5459143 ],\n",
       "       [1.        ],\n",
       "       [0.11646842],\n",
       "       [0.9999988 ],\n",
       "       [0.02430666],\n",
       "       [0.21426529],\n",
       "       [0.10486617],\n",
       "       [1.        ],\n",
       "       [0.42129064],\n",
       "       [0.00416808],\n",
       "       [0.20992957],\n",
       "       [0.13373114],\n",
       "       [0.56278366],\n",
       "       [0.13283683],\n",
       "       [0.0061297 ],\n",
       "       [0.1205274 ],\n",
       "       [1.        ],\n",
       "       [0.10117079],\n",
       "       [0.15478987],\n",
       "       [0.00000016],\n",
       "       [1.        ],\n",
       "       [0.6603279 ],\n",
       "       [0.58206517],\n",
       "       [0.11753929],\n",
       "       [0.00004959],\n",
       "       [0.11107904],\n",
       "       [0.7970132 ],\n",
       "       [0.9999997 ],\n",
       "       [0.11107269],\n",
       "       [0.011532  ],\n",
       "       [0.00000016],\n",
       "       [0.99047613],\n",
       "       [0.17532448],\n",
       "       [1.        ],\n",
       "       [0.14820206],\n",
       "       [0.04125755],\n",
       "       [0.5406528 ],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [0.99959993],\n",
       "       [0.13591999],\n",
       "       [1.        ],\n",
       "       [0.11458431],\n",
       "       [0.00034466],\n",
       "       [0.61067045],\n",
       "       [0.9999995 ],\n",
       "       [0.32451224],\n",
       "       [0.18369435],\n",
       "       [1.        ],\n",
       "       [0.3115015 ],\n",
       "       [0.12558766],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.00246985],\n",
       "       [0.10341252],\n",
       "       [0.00227779],\n",
       "       [0.00657521],\n",
       "       [0.04125755],\n",
       "       [0.05694773],\n",
       "       [0.2940587 ],\n",
       "       [0.35306957],\n",
       "       [0.13025871],\n",
       "       [0.9996083 ],\n",
       "       [0.12128477],\n",
       "       [0.2046127 ],\n",
       "       [0.05662141],\n",
       "       [0.00205514],\n",
       "       [0.0132517 ],\n",
       "       [1.        ],\n",
       "       [0.99999994],\n",
       "       [0.12686099],\n",
       "       [0.00000357],\n",
       "       [0.96083945],\n",
       "       [0.05737503],\n",
       "       [0.9999995 ],\n",
       "       [0.11426603],\n",
       "       [0.03613915],\n",
       "       [1.        ],\n",
       "       [0.04884486],\n",
       "       [0.99999833],\n",
       "       [0.20141602],\n",
       "       [0.96109056],\n",
       "       [0.18865877],\n",
       "       [0.18979551],\n",
       "       [0.00219773],\n",
       "       [0.7268672 ],\n",
       "       [0.85731477],\n",
       "       [0.72684216],\n",
       "       [1.        ],\n",
       "       [0.12554008],\n",
       "       [0.14873789],\n",
       "       [1.        ],\n",
       "       [0.17650524],\n",
       "       [0.14873789],\n",
       "       [0.8909575 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all = model.predict(X_pred)\n",
    "#predicted_data = pd.DataFrame(y_pred_all)\n",
    "np.set_printoptions(suppress=True)\n",
    "y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1687ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all = [0 if i <=0.5 else 1 for i in y_pred_all]\n",
    "y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b1c7e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert numpy ndarray back to dataframe\n",
    "predicted_data = pd.DataFrame(y_pred_all)\n",
    "\n",
    "# append the predicted data to final file\n",
    "df_test = pd.read_csv('titanic_test_data.csv')\n",
    "df_test = pd.concat([df_test,predicted_data],axis=1) # append predicted y\n",
    "df_test = df_test.rename(columns = {0:'Survived'}) # rename added column\n",
    "df_test = df_test[['PassengerId', 'Survived']] # leave only requested columns for submit\n",
    "df_test # check if correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff26c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "df_test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8914a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
